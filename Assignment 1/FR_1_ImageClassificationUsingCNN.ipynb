{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries \n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator #To shuffle images\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D #Conv2D stands for a 2-dimensional convolutional layer.\n",
    "from keras.layers import Activation #Activation function\n",
    "from keras.layers import MaxPooling2D #Max Pooling layer\n",
    "from keras.layers import Dense #Dense layer\n",
    "from keras.layers import Flatten #Flatter \n",
    "from keras.layers import Dropout #Dropout for overfitting/underfitting\n",
    "from keras import backend as K \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting image height and width\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining data directory\n",
    "train_data_dir = 'D:/DATASCIENCE/binary_data_cnn/Train'\n",
    "validation_data_dir = 'D:/DATASCIENCE/binary_data_cnn/Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining samples count of train and test data\n",
    "nb_train_samples =400\n",
    "nb_validation_samples = 100\n",
    "epochs = 10\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formating RGB channel with size\n",
    "\n",
    "if K.image_data_format() == 'channels_first': \n",
    "    input_shape = (3, img_width, img_height) \n",
    "else: \n",
    "    input_shape = (img_width, img_height, 3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing a convonutional neural nw  using sequential model of keras\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding convolutional layers\n",
    "\n",
    "model.add(Conv2D(32,(2,2),input_shape=input_shape))\n",
    "\n",
    "#32 is the value of filter\n",
    "#(2,2) is the size of the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Activation layer\n",
    "\n",
    "model.add(Activation('relu')) #Adding Relu activation function to get the output from neuron\n",
    "\n",
    "#Relu replaces all the -ve pixels in the feature map with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Pooling layer\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#We are using 2*2 size of filter for pooling.\n",
    "#It will fetch max value from each pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard convolutionnal NN has 3 blocks followed by a connected layer.\n",
    "\n",
    "#Creating two more layers\n",
    "model.add(Conv2D(32,(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding dropout\n",
    "\n",
    "#We will use droupout to prevent overfitting\n",
    "\n",
    "#To prepare out model for dropout, we first flatten the feature map to 1-dimension\n",
    "\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will initialize a fully connected network by using Dense function and apply Relu activation function to it.\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Dropout layer\n",
    "\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will initialize one more fully connected layer. \n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying sigmoid function\n",
    "\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 223, 223, 32)      416       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 223, 223, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 110, 110, 32)      4128      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 54, 54, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 23328)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1493056   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,501,793\n",
      "Trainable params: 1,501,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#summary of CNN\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model using compile()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "            optimizer='rmsprop', \n",
    "            metrics=['accuracy']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer rmsprop will perform gradient descent for this model. Gradient descent is actually an optimization algorithm which helps to find the minimum value of a function.\n",
    "##The binary_crossentropy is the best loss function for binary classification problems\n",
    "#We have set metrics to accuracy to get accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using data augmentation\n",
    "\n",
    "#By usiing data augmentation we can flip, zoom and can do many things with images, so that machine will get variety of images.\n",
    "\n",
    "#TO do so we will use ImageDataGenerator \n",
    "\n",
    "train_datagen = ImageDataGenerator( \n",
    "    rescale=1. / 255, \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True) \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Train and Test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Setting train and test directories using flow_from_directory() \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory( \n",
    "    train_data_dir, \n",
    "    target_size=(img_width, img_height), \n",
    "    batch_size=batch_size, \n",
    "    class_mode='binary') \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( \n",
    "    validation_data_dir, \n",
    "    target_size=(img_width, img_height), \n",
    "    batch_size=batch_size, \n",
    "    class_mode='binary') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-7a1666e30d88>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 17s 700ms/step - loss: 0.8484 - accuracy: 0.6150 - val_loss: 0.4661 - val_accuracy: 0.8854\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 17s 680ms/step - loss: 0.5868 - accuracy: 0.6950 - val_loss: 0.3630 - val_accuracy: 0.8646\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 18s 709ms/step - loss: 0.5436 - accuracy: 0.7850 - val_loss: 0.3139 - val_accuracy: 0.9271\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 17s 683ms/step - loss: 0.4290 - accuracy: 0.8050 - val_loss: 0.3321 - val_accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 17s 680ms/step - loss: 0.4070 - accuracy: 0.8375 - val_loss: 0.2469 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 17s 680ms/step - loss: 0.4065 - accuracy: 0.8575 - val_loss: 0.8429 - val_accuracy: 0.6875\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 17s 684ms/step - loss: 0.3262 - accuracy: 0.8625 - val_loss: 0.2835 - val_accuracy: 0.8646\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 17s 676ms/step - loss: 0.3434 - accuracy: 0.8625 - val_loss: 0.5473 - val_accuracy: 0.6979\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 17s 680ms/step - loss: 0.2886 - accuracy: 0.8825 - val_loss: 0.3034 - val_accuracy: 0.8542\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 17s 682ms/step - loss: 0.2556 - accuracy: 0.9075 - val_loss: 0.2964 - val_accuracy: 0.8646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17d80aad288>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator( \n",
    "    train_generator, \n",
    "    steps_per_epoch=nb_train_samples // batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_data=validation_generator, \n",
    "    validation_steps=nb_validation_samples // batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting accuracy of 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model for testing\n",
    "from keras.models import load_model \n",
    "classifier = load_model('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Loading image from drive\n",
    "test_image =image.load_img('D:/DATASCIENCE/binary_data_cnn/manual_test/5.jpg',target_size =(224,224))\n",
    "\n",
    "#Converting image to array\n",
    "test_image =image.img_to_array(test_image)\n",
    "test_image =np.expand_dims(test_image, axis =0)\n",
    "\n",
    "#Predicting image\n",
    "result = classifier.predict(test_image)\n",
    "if result[0][0] >= 0.5:\n",
    "    prediction = 'plane'\n",
    "else:\n",
    "    prediction = 'car'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is predicting well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

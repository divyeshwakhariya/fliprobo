{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid</td>\n",
       "      <td>Coronaviruses are a large family of viruses th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ai</td>\n",
       "      <td>Artificial intelligence (AI), sometimes called...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neural link</td>\n",
       "      <td>Neuralink is a device that will be surgically ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gdp</td>\n",
       "      <td>\\nWhat is Gross Domestic Product (GDP)?\\nBy: F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ipl</td>\n",
       "      <td>The Indian Premier League (IPL) is a professio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ssr</td>\n",
       "      <td>The AIIMS medical board will hold a meeting wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jee</td>\n",
       "      <td>The Ministry of Human Resource Development, Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>global warming</td>\n",
       "      <td>Global Warming is a term almost everyone is fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>space</td>\n",
       "      <td>Indian space programme encompasses research in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>football</td>\n",
       "      <td>Football is a family of team sports that invol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cricket</td>\n",
       "      <td>Cricket : A Gentlemen's Game!\\nCricket was inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>computer</td>\n",
       "      <td>A computer is a programmable electronic device...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>religion</td>\n",
       "      <td>Religion\\nReligion is an organized collection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>carpool</td>\n",
       "      <td>Carpool is the original ride sharing. Basicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>politics</td>\n",
       "      <td>The simple answer to this question is that the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>farming agriculture</td>\n",
       "      <td>Farming is the practice of cultivating the lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5G</td>\n",
       "      <td>In telecommunications, 5G is the fifth generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>self driving car</td>\n",
       "      <td>An autonomous car is a vehicle capable of sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pubg</td>\n",
       "      <td>PUBG is the first of what is now called the Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>agile</td>\n",
       "      <td>Agile software development refers to  software...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  topic                                            content\n",
       "0                 covid  Coronaviruses are a large family of viruses th...\n",
       "1                    ai  Artificial intelligence (AI), sometimes called...\n",
       "2           neural link  Neuralink is a device that will be surgically ...\n",
       "3                   gdp  \\nWhat is Gross Domestic Product (GDP)?\\nBy: F...\n",
       "4                   ipl  The Indian Premier League (IPL) is a professio...\n",
       "5                   ssr  The AIIMS medical board will hold a meeting wi...\n",
       "6                   jee  The Ministry of Human Resource Development, Go...\n",
       "7        global warming  Global Warming is a term almost everyone is fa...\n",
       "8                 space  Indian space programme encompasses research in...\n",
       "9              football  Football is a family of team sports that invol...\n",
       "10              cricket  Cricket : A Gentlemen's Game!\\nCricket was inv...\n",
       "11             computer  A computer is a programmable electronic device...\n",
       "12             religion  Religion\\nReligion is an organized collection ...\n",
       "13              carpool  Carpool is the original ride sharing. Basicall...\n",
       "14             politics  The simple answer to this question is that the...\n",
       "15  farming agriculture  Farming is the practice of cultivating the lan...\n",
       "16                   5G  In telecommunications, 5G is the fifth generat...\n",
       "17     self driving car  An autonomous car is a vehicle capable of sens...\n",
       "18                 pubg  PUBG is the first of what is now called the Ba...\n",
       "19                agile  Agile software development refers to  software..."
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[0:15]\n",
    "df_test = df.iloc[15:21,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  (15, 2)  Testing data:  (5, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data: \",df_train.shape,\" Testing data: \",df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_processing(text):\n",
    "    \n",
    "    #Lower case the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    #normalizing URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    #normalizing email ids\n",
    "    text = re.sub('([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,})', '', text)\n",
    "    \n",
    "    # replace dollar with dollar\n",
    "    text = re.sub(r'£|\\$', ' ', text)\n",
    "    \n",
    "    #replace mobile number with strig mobilenumber\n",
    "    text = re.sub('(?:\\+ *)?\\d[\\d\\- ]{7,}\\d', '', text)\n",
    "    \n",
    "    #replace any numbers with string 'numbr'\n",
    "    text = re.sub(r'\\d+(\\.\\d+)?', ' ',text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.replace(r'[^\\w\\d\\s]', ' ')\n",
    "    text = text.replace('\\\\n', \" \") \n",
    "    text = text.replace('\\\\\\n', \" \") \n",
    "    text = text.replace('\\n', \" \")\n",
    "    text = text.replace(r'“', \" \")\n",
    "    text = text.replace(r'”', \" \")\n",
    "    \n",
    "    \n",
    "    # define punctuation\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punct = \"\"\n",
    "    for char in text:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "\n",
    "    \n",
    "\n",
    "    # Replace whitespace between terms with a single space\n",
    "    text = no_punct.replace(r'\\s+', ' ')\n",
    "\n",
    "    # Remove leading and trailing whitespace\n",
    "    text = text.replace(r'^\\s+|\\s+?$', '')\n",
    "    \n",
    "    #Tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    \n",
    "    #Removing stopwords\n",
    "    stopword = gensim.parsing.preprocessing.STOPWORDS\n",
    "    review_text = [word for word in text if word not in stopword if(len(word)>3)]\n",
    "    \n",
    "    #Lemmatize words\n",
    "    \n",
    "    clean_text = []\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    for word in review_text:\n",
    "        if(len(word)>3):\n",
    "            clean = stemmer.stem(WordNetLemmatizer().lemmatize(word,pos='v'))\n",
    "            clean_text.append(word)\n",
    "    \n",
    "    #review_text = ([wnl.lemmatize(word,pos = \"v\") for word in text if(len(word)>3)])\n",
    "    \n",
    "    \n",
    "   \n",
    "    return review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Document: \n",
      "['After', 'completion,', '()\\n\\n', 'upload', 'your', 'solutions', 'in', 'the', 'worksheets', 'repository', 'of', 'your', 'GitHub', 'profile', 'and', 'share', 'that', 'link', 'with', 'us.', '']\n",
      "\n",
      "\n",
      "Tokenized and lemmatized document: \n",
      "['completion', 'upload', 'solutions', 'worksheets', 'repository', 'github', 'profile', 'share', 'link']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = 'After completion, ()\\n\\n upload your solutions in the worksheets repository of your GitHub profile and share that link with us. '\n",
    "\n",
    "print(\"Original Document: \")\n",
    "words=[]\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print(\"\\n\\nTokenized and lemmatized document: \")\n",
    "print(data_processing(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = []\n",
    "\n",
    "for doc in df_train.content:\n",
    "    doc1 = data_processing(doc)\n",
    "    doc1 = ' '.join(doc1)\n",
    "    processed_text.append(data_processing(doc1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['coronaviruses', 'large', 'family', 'viruses', 'actually', 'common', 'world', 'cause', 'respiratory', 'illness', 'people', 'animals', 'known', 'coronaviruses', 'infect', 'people', 'usually', 'cause', 'mild', 'respiratory', 'disease', 'common', 'cold', 'previously', 'identified', 'coronaviruses', 'caused', 'severe', 'illness', 'severe', 'acute', 'respiratory', 'syndrome', 'sars', 'coronavirus', 'middle', 'east', 'respiratory', 'syndrome', 'mers', 'coronavirus', 'whats', 'different', 'coronavirus', 'covid', 'coronaviruses', 'common', 'coronavirus', 'covid', 'strain', 'coronavirus', 'previously', 'identified', 'humans', 'features', 'covid', 'respiratory', 'symptoms', 'fever', 'cough', 'like', 'infections', 'understanding', 'covid', 'important', 'changes', 'rapidly', 'proactively', 'monitoring', 'virus', 'taking', 'measures', 'like', 'providing', 'guidance', 'health', 'care', 'workers', 'issuing', 'travel', 'recommendations', 'coronaviruses', 'spread', 'investigation', 'covid', 'ongoing', 'human', 'coronaviruses', 'spread', 'persontoperson', 'contact', 'similar', 'cold', 'person', 'sick', 'close', 'contact', 'infected', 'person', 'virus', 'spread', 'respiratory', 'droplets', 'produced', 'infected', 'person', 'coughing', 'sneezing', 'touching', 'surfaces', 'virus', 'signs', 'symptoms', 'coronaviruses', 'confirmed', 'cases', 'covid', 'infections', 'symptoms', 'include', 'fever', 'cough', 'shortness', 'breath', 'severity', 'ranged', 'mild', 'people', 'severely', 'virus', 'causes', 'covid', 'spreading', 'easily', 'sustainably', 'community', 'community', 'spread', 'affected', 'geographic', 'areas', 'community', 'spread', 'means', 'people', 'infected', 'virus', 'area', 'including', 'sure', 'infected'], ['artificial', 'intelligence', 'called', 'machine', 'intelligence', 'intelligence', 'demonstrated', 'machines', 'unlike', 'natural', 'intelligence', 'displayed', 'humans', 'animals', 'leading', 'textbooks', 'define', 'field', 'study', 'intelligent', 'agents', 'device', 'perceives', 'environment', 'takes', 'actions', 'maximize', 'chance', 'successfully', 'achieving', 'goals', 'colloquially', 'term', 'artificial', 'intelligence', 'machines', 'computers', 'mimic', 'cognitive', 'functions', 'humans', 'associate', 'human', 'mind', 'learning', 'problem', 'solving', 'machines', 'increasingly', 'capable', 'tasks', 'considered', 'require', 'intelligence', 'removed', 'definition', 'phenomenon', 'known', 'effect', 'quip', 'teslers', 'theorem', 'says', 'instance', 'optical', 'character', 'recognition', 'frequently', 'excluded', 'things', 'considered', 'having', 'routine', 'technology', 'modern', 'machine', 'capabilities', 'generally', 'classified', 'include', 'successfully', 'understanding', 'human', 'speech', 'competing', 'highest', 'level', 'strategic', 'game', 'systems', 'chess', 'autonomously', 'operating', 'cars', 'intelligent', 'routing', 'content', 'delivery', 'networks', 'military', 'simulations', 'artificial', 'intelligence', 'founded', 'academic', 'discipline', 'years', 'experienced', 'waves', 'optimism', 'followed', 'disappointment', 'loss', 'funding', 'known', 'winter', 'followed', 'approaches', 'success', 'renewed', 'funding', 'history', 'research', 'divided', 'subfields', 'fail', 'communicate', 'subfields', 'based', 'technical', 'considerations', 'particular', 'goals', 'robotics', 'machine', 'learning', 'particular', 'tools', 'logic', 'artificial', 'neural', 'networks', 'deep', 'philosophical', 'differences', 'subfields', 'based', 'social', 'factors', 'particular', 'institutions', 'work', 'particular', 'researchers', 'traditional', 'problems', 'goals', 'research', 'include', 'reasoning', 'knowledge', 'representation', 'planning', 'learning', 'natural', 'language', 'processing', 'perception', 'ability', 'manipulate', 'objects', 'general', 'intelligence', 'fields', 'longterm', 'goals', 'approaches', 'include', 'statistical', 'methods', 'computational', 'intelligence', 'traditional', 'symbolic', 'tools', 'including', 'versions', 'search', 'mathematical', 'optimization', 'artificial', 'neural', 'networks', 'methods', 'based', 'statistics', 'probability', 'economics', 'field', 'draws', 'science', 'information', 'engineering', 'mathematics', 'psychology', 'linguistics', 'philosophy', 'fields', 'field', 'founded', 'assumption', 'human', 'intelligence', 'precisely', 'described', 'machine', 'simulate', 'raises', 'philosophical', 'arguments', 'mind', 'ethics', 'creating', 'artificial', 'beings', 'endowed', 'humanlike', 'intelligence', 'issues', 'explored', 'myth', 'fiction', 'philosophy', 'antiquity', 'people', 'consider', 'danger', 'humanity', 'progresses', 'unabated', 'believe', 'unlike', 'previous', 'technological', 'revolutions', 'create', 'risk', 'mass', 'unemployment']]\n"
     ]
    }
   ],
   "source": [
    "print(processed_text[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have preprocessed our data by cleaning, removing stopwords, removin puncuations, and by lemmatizing words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words on the data set\n",
    "dictionary = Dictionary(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1526 unique tokens: ['actually', 'acute', 'affected', 'animals', 'area']...)\n"
     ]
    }
   ],
   "source": [
    "print (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
    "#words and how many times those words appear. Save this to 'bow_corpus'\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 1),\n",
       " (35, 3),\n",
       " (36, 2),\n",
       " (40, 3),\n",
       " (41, 1),\n",
       " (47, 2),\n",
       " (57, 1),\n",
       " (88, 1),\n",
       " (95, 1),\n",
       " (96, 1),\n",
       " (97, 1),\n",
       " (98, 1),\n",
       " (99, 1),\n",
       " (100, 1),\n",
       " (101, 2),\n",
       " (102, 1),\n",
       " (103, 6),\n",
       " (104, 1),\n",
       " (105, 1),\n",
       " (106, 1),\n",
       " (107, 3),\n",
       " (108, 1),\n",
       " (109, 1),\n",
       " (110, 1),\n",
       " (111, 1),\n",
       " (112, 1),\n",
       " (113, 1),\n",
       " (114, 1),\n",
       " (115, 1),\n",
       " (116, 1),\n",
       " (117, 1),\n",
       " (118, 1),\n",
       " (119, 1),\n",
       " (120, 1),\n",
       " (121, 1),\n",
       " (122, 1),\n",
       " (123, 1),\n",
       " (124, 1),\n",
       " (125, 1),\n",
       " (126, 2),\n",
       " (127, 1),\n",
       " (128, 1),\n",
       " (129, 1),\n",
       " (130, 1),\n",
       " (131, 1),\n",
       " (132, 1),\n",
       " (133, 1),\n",
       " (134, 1),\n",
       " (135, 1),\n",
       " (136, 1),\n",
       " (137, 1),\n",
       " (138, 1),\n",
       " (139, 1),\n",
       " (140, 1),\n",
       " (141, 1),\n",
       " (142, 1),\n",
       " (143, 1),\n",
       " (144, 1),\n",
       " (145, 1),\n",
       " (146, 1),\n",
       " (147, 1),\n",
       " (148, 1),\n",
       " (149, 1),\n",
       " (150, 1),\n",
       " (151, 1),\n",
       " (152, 1),\n",
       " (153, 1),\n",
       " (154, 1),\n",
       " (155, 1),\n",
       " (156, 3),\n",
       " (157, 2),\n",
       " (158, 2),\n",
       " (159, 2),\n",
       " (160, 1),\n",
       " (161, 1),\n",
       " (162, 2),\n",
       " (163, 1),\n",
       " (164, 1),\n",
       " (165, 1),\n",
       " (166, 4),\n",
       " (167, 1),\n",
       " (168, 1),\n",
       " (169, 1),\n",
       " (170, 1),\n",
       " (171, 1),\n",
       " (172, 1),\n",
       " (173, 1),\n",
       " (174, 1),\n",
       " (175, 1),\n",
       " (176, 11),\n",
       " (177, 2),\n",
       " (178, 1),\n",
       " (179, 1),\n",
       " (180, 1),\n",
       " (181, 1),\n",
       " (182, 3),\n",
       " (183, 1),\n",
       " (184, 1),\n",
       " (185, 1),\n",
       " (186, 1),\n",
       " (187, 1),\n",
       " (188, 4),\n",
       " (189, 3),\n",
       " (190, 1),\n",
       " (191, 1),\n",
       " (192, 1),\n",
       " (193, 1),\n",
       " (194, 1),\n",
       " (195, 2),\n",
       " (196, 1),\n",
       " (197, 1),\n",
       " (198, 2),\n",
       " (199, 1),\n",
       " (200, 1),\n",
       " (201, 2),\n",
       " (202, 3),\n",
       " (203, 2),\n",
       " (204, 1),\n",
       " (205, 1),\n",
       " (206, 1),\n",
       " (207, 1),\n",
       " (208, 1),\n",
       " (209, 4),\n",
       " (210, 1),\n",
       " (211, 1),\n",
       " (212, 1),\n",
       " (213, 2),\n",
       " (214, 2),\n",
       " (215, 1),\n",
       " (216, 1),\n",
       " (217, 1),\n",
       " (218, 1),\n",
       " (219, 1),\n",
       " (220, 1),\n",
       " (221, 1),\n",
       " (222, 1),\n",
       " (223, 1),\n",
       " (224, 1),\n",
       " (225, 1),\n",
       " (226, 1),\n",
       " (227, 1),\n",
       " (228, 1),\n",
       " (229, 1),\n",
       " (230, 1),\n",
       " (231, 1),\n",
       " (232, 2),\n",
       " (233, 1),\n",
       " (234, 1),\n",
       " (235, 1),\n",
       " (236, 1),\n",
       " (237, 1),\n",
       " (238, 1),\n",
       " (239, 1),\n",
       " (240, 1),\n",
       " (241, 1),\n",
       " (242, 1),\n",
       " (243, 1),\n",
       " (244, 1),\n",
       " (245, 1),\n",
       " (246, 1),\n",
       " (247, 1),\n",
       " (248, 1),\n",
       " (249, 1),\n",
       " (250, 1),\n",
       " (251, 3),\n",
       " (252, 1),\n",
       " (253, 2),\n",
       " (254, 1),\n",
       " (255, 1),\n",
       " (256, 1),\n",
       " (257, 1),\n",
       " (258, 1),\n",
       " (259, 1),\n",
       " (260, 1),\n",
       " (261, 1),\n",
       " (262, 1),\n",
       " (263, 1),\n",
       " (264, 1),\n",
       " (265, 1),\n",
       " (266, 2),\n",
       " (267, 2),\n",
       " (268, 1),\n",
       " (269, 1),\n",
       " (270, 2),\n",
       " (271, 1),\n",
       " (272, 1),\n",
       " (273, 1),\n",
       " (274, 1),\n",
       " (275, 1)]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 80 (\"sure\") appears 1 time.\n",
      "Word 97 (\"achieving\") appears 1 time.\n",
      "Word 153 (\"factors\") appears 1 time.\n",
      "Word 157 (\"fields\") appears 1 time.\n",
      "Word 161 (\"functions\") appears 1 time.\n",
      "Word 163 (\"game\") appears 8 time.\n",
      "Word 201 (\"natural\") appears 1 time.\n",
      "Word 345 (\"place\") appears 1 time.\n",
      "Word 348 (\"played\") appears 1 time.\n",
      "Word 357 (\"right\") appears 1 time.\n",
      "Word 377 (\"team\") appears 5 time.\n",
      "Word 482 (\"number\") appears 1 time.\n",
      "Word 519 (\"time\") appears 2 time.\n",
      "Word 545 (\"committee\") appears 1 time.\n",
      "Word 549 (\"cricket\") appears 10 time.\n",
      "Word 564 (\"international\") appears 2 time.\n",
      "Word 580 (\"players\") appears 3 time.\n",
      "Word 583 (\"prevent\") appears 1 time.\n",
      "Word 598 (\"teams\") appears 1 time.\n",
      "Word 717 (\"talent\") appears 2 time.\n",
      "Word 756 (\"especially\") appears 1 time.\n",
      "Word 783 (\"national\") appears 1 time.\n",
      "Word 808 (\"score\") appears 3 time.\n",
      "Word 809 (\"scores\") appears 1 time.\n",
      "Word 821 (\"test\") appears 2 time.\n",
      "Word 825 (\"twice\") appears 1 time.\n",
      "Word 996 (\"unique\") appears 1 time.\n",
      "Word 1005 (\"ball\") appears 1 time.\n",
      "Word 1009 (\"century\") appears 1 time.\n",
      "Word 1028 (\"england\") appears 1 time.\n",
      "Word 1039 (\"goal\") appears 1 time.\n",
      "Word 1064 (\"popular\") appears 2 time.\n",
      "Word 1075 (\"scoring\") appears 1 time.\n",
      "Word 1089 (\"achieve\") appears 1 time.\n",
      "Word 1090 (\"achrekar\") appears 1 time.\n",
      "Word 1091 (\"arena\") appears 1 time.\n",
      "Word 1092 (\"aristocrats\") appears 1 time.\n",
      "Word 1093 (\"assist\") appears 1 time.\n",
      "Word 1094 (\"balls\") appears 3 time.\n",
      "Word 1095 (\"bats\") appears 1 time.\n",
      "Word 1096 (\"batsmen\") appears 11 time.\n",
      "Word 1097 (\"batting\") appears 1 time.\n",
      "Word 1098 (\"benevolence\") appears 1 time.\n",
      "Word 1099 (\"bowled\") appears 1 time.\n",
      "Word 1100 (\"bowler\") appears 3 time.\n",
      "Word 1101 (\"bowling\") appears 1 time.\n",
      "Word 1102 (\"bowls\") appears 2 time.\n",
      "Word 1103 (\"boys\") appears 1 time.\n",
      "Word 1104 (\"captain\") appears 1 time.\n",
      "Word 1105 (\"coach\") appears 1 time.\n",
      "Word 1106 (\"coached\") appears 1 time.\n",
      "Word 1107 (\"crowd\") appears 1 time.\n",
      "Word 1108 (\"crowds\") appears 1 time.\n",
      "Word 1109 (\"days\") appears 1 time.\n",
      "Word 1110 (\"decides\") appears 1 time.\n",
      "Word 1111 (\"deciding\") appears 1 time.\n",
      "Word 1112 (\"definite\") appears 1 time.\n",
      "Word 1113 (\"dismissed\") appears 1 time.\n",
      "Word 1114 (\"englands\") appears 1 time.\n",
      "Word 1115 (\"everybody\") appears 1 time.\n",
      "Word 1116 (\"famous\") appears 1 time.\n",
      "Word 1117 (\"fielder\") appears 1 time.\n",
      "Word 1118 (\"fielding\") appears 1 time.\n",
      "Word 1119 (\"flair\") appears 1 time.\n",
      "Word 1120 (\"flock\") appears 1 time.\n",
      "Word 1121 (\"format\") appears 1 time.\n",
      "Word 1122 (\"formats\") appears 2 time.\n",
      "Word 1123 (\"gentlemens\") appears 1 time.\n",
      "Word 1124 (\"getting\") appears 1 time.\n",
      "Word 1125 (\"goes\") appears 1 time.\n",
      "Word 1126 (\"good\") appears 2 time.\n",
      "Word 1127 (\"great\") appears 2 time.\n",
      "Word 1128 (\"ground\") appears 2 time.\n",
      "Word 1129 (\"herded\") appears 1 time.\n",
      "Word 1130 (\"hysteria\") appears 1 time.\n",
      "Word 1131 (\"immortality\") appears 1 time.\n",
      "Word 1132 (\"invented\") appears 1 time.\n",
      "Word 1133 (\"involves\") appears 1 time.\n",
      "Word 1134 (\"juans\") appears 1 time.\n",
      "Word 1135 (\"later\") appears 1 time.\n",
      "Word 1136 (\"london\") appears 1 time.\n",
      "Word 1137 (\"love\") appears 1 time.\n",
      "Word 1138 (\"loves\") appears 1 time.\n",
      "Word 1139 (\"mainly\") appears 1 time.\n",
      "Word 1140 (\"making\") appears 1 time.\n",
      "Word 1141 (\"numerous\") appears 1 time.\n",
      "Word 1142 (\"obviously\") appears 1 time.\n",
      "Word 1143 (\"ones\") appears 1 time.\n",
      "Word 1144 (\"outscore\") appears 1 time.\n",
      "Word 1145 (\"performing\") appears 1 time.\n",
      "Word 1146 (\"permits\") appears 1 time.\n",
      "Word 1147 (\"phrase\") appears 1 time.\n",
      "Word 1148 (\"quote\") appears 1 time.\n",
      "Word 1149 (\"reach\") appears 1 time.\n",
      "Word 1150 (\"recognize\") appears 1 time.\n",
      "Word 1151 (\"revolves\") appears 1 time.\n",
      "Word 1152 (\"runs\") appears 4 time.\n",
      "Word 1153 (\"sachin\") appears 1 time.\n",
      "Word 1154 (\"separates\") appears 1 time.\n",
      "Word 1155 (\"shepherds\") appears 1 time.\n",
      "Word 1156 (\"shown\") appears 1 time.\n",
      "Word 1157 (\"stands\") appears 1 time.\n",
      "Word 1158 (\"stature\") appears 1 time.\n",
      "Word 1159 (\"style\") appears 1 time.\n",
      "Word 1160 (\"supposedly\") appears 1 time.\n",
      "Word 1161 (\"tendulkar\") appears 1 time.\n",
      "Word 1162 (\"thing\") appears 1 time.\n",
      "Word 1163 (\"toss\") appears 1 time.\n",
      "Word 1164 (\"tries\") appears 2 time.\n",
      "Word 1165 (\"vast\") appears 1 time.\n",
      "Word 1166 (\"wallop\") appears 1 time.\n",
      "Word 1167 (\"whip\") appears 1 time.\n",
      "Word 1168 (\"wins\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "#preview \n",
    "document_num = 10\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]],\n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 15, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 5,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.045*\"mission\" + 0.018*\"mars\" + 0.015*\"chandrayaan\" + 0.015*\"orbiter\" + 0.015*\"astrosat\" + 0.012*\"orbit\" + 0.012*\"space\" + 0.012*\"spacecraft\" + 0.009*\"xray\" + 0.009*\"module\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.002*\"politics\" + 0.002*\"team\" + 0.001*\"batsmen\" + 0.001*\"aiims\" + 0.001*\"cricket\" + 0.001*\"medical\" + 0.001*\"data\" + 0.001*\"singh\" + 0.001*\"game\" + 0.001*\"political\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.016*\"country\" + 0.016*\"economic\" + 0.016*\"product\" + 0.013*\"domestic\" + 0.013*\"data\" + 0.013*\"gross\" + 0.013*\"services\" + 0.011*\"transmission\" + 0.011*\"factor\" + 0.011*\"numbers\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.002*\"entrance\" + 0.001*\"main\" + 0.001*\"exam\" + 0.001*\"examination\" + 0.001*\"examinations\" + 0.001*\"year\" + 0.001*\"conduct\" + 0.001*\"india\" + 0.001*\"april\" + 0.001*\"mission\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.002*\"brain\" + 0.002*\"control\" + 0.002*\"device\" + 0.002*\"data\" + 0.002*\"wires\" + 0.002*\"neuralink\" + 0.002*\"warming\" + 0.002*\"place\" + 0.001*\"global\" + 0.001*\"size\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.002*\"politics\" + 0.001*\"team\" + 0.001*\"coronaviruses\" + 0.001*\"football\" + 0.001*\"political\" + 0.001*\"covid\" + 0.001*\"cricket\" + 0.001*\"concepts\" + 0.001*\"virus\" + 0.001*\"different\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.040*\"batsmen\" + 0.037*\"cricket\" + 0.029*\"game\" + 0.018*\"team\" + 0.015*\"runs\" + 0.011*\"score\" + 0.011*\"players\" + 0.011*\"bowler\" + 0.011*\"balls\" + 0.008*\"bowls\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.002*\"football\" + 0.002*\"team\" + 0.001*\"mission\" + 0.001*\"league\" + 0.001*\"board\" + 0.001*\"cricket\" + 0.001*\"players\" + 0.001*\"aiims\" + 0.001*\"india\" + 0.001*\"ball\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.027*\"covid\" + 0.027*\"coronaviruses\" + 0.023*\"respiratory\" + 0.019*\"coronavirus\" + 0.019*\"spread\" + 0.019*\"virus\" + 0.016*\"people\" + 0.016*\"infected\" + 0.012*\"community\" + 0.012*\"symptoms\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.029*\"religious\" + 0.021*\"religions\" + 0.021*\"religion\" + 0.013*\"belief\" + 0.009*\"world\" + 0.009*\"people\" + 0.009*\"multiple\" + 0.009*\"principles\" + 0.009*\"life\" + 0.009*\"follow\"\n",
      "\n",
      "\n",
      "Topic: 10 \n",
      "Words: 0.020*\"global\" + 0.020*\"entrance\" + 0.020*\"warming\" + 0.017*\"main\" + 0.017*\"exam\" + 0.013*\"board\" + 0.012*\"india\" + 0.010*\"cricket\" + 0.010*\"examination\" + 0.010*\"causes\"\n",
      "\n",
      "\n",
      "Topic: 11 \n",
      "Words: 0.044*\"football\" + 0.038*\"politics\" + 0.019*\"political\" + 0.013*\"codes\" + 0.013*\"ball\" + 0.011*\"concepts\" + 0.010*\"players\" + 0.008*\"rugby\" + 0.008*\"rules\" + 0.008*\"definitions\"\n",
      "\n",
      "\n",
      "Topic: 12 \n",
      "Words: 0.020*\"intelligence\" + 0.017*\"brain\" + 0.015*\"neuralink\" + 0.011*\"artificial\" + 0.009*\"machines\" + 0.009*\"place\" + 0.009*\"inside\" + 0.009*\"wires\" + 0.008*\"device\" + 0.007*\"particular\"\n",
      "\n",
      "\n",
      "Topic: 13 \n",
      "Words: 0.030*\"team\" + 0.019*\"aiims\" + 0.015*\"singh\" + 0.015*\"medical\" + 0.013*\"carpool\" + 0.012*\"forensic\" + 0.011*\"share\" + 0.010*\"death\" + 0.010*\"mumbai\" + 0.009*\"board\"\n",
      "\n",
      "\n",
      "Topic: 14 \n",
      "Words: 0.029*\"data\" + 0.020*\"output\" + 0.018*\"device\" + 0.016*\"memory\" + 0.012*\"programs\" + 0.012*\"input\" + 0.012*\"software\" + 0.012*\"hardware\" + 0.012*\"components\" + 0.012*\"parts\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics():\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are have successfully created a topic modeling on our train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check it on our test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on unknown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In telecommunications, 5G is the fifth generation technology standard for cellular networks, which cellular phone companies began deploying worldwide in 2019, the planned successor to the 4G networks which provide connectivity to most current cellphones.[1] Like its predecessors, 5G networks are cellular networks, in which the service area is divided into small geographical areas called cells. All 5G wireless devices in a cell are connected to the Internet and telephone network by radio waves through a local antenna in the cell. The main advantage of the new networks is that they will have greater bandwidth, giving higher download speeds,[1] eventually up to 10 gigabits per second (Gbit/s).[2] Due to the increased bandwidth, it is expected that the new networks will not just serve cellphones like existing cellular networks, but also be used as general internet service providers for laptops and desktop computers, competing with existing ISPs such as cable internet, and also will make possible new applications in internet of things (IoT) and machine to machine areas. Current 4G cellphones will not be able to use the new networks, which will require new 5G enabled wireless devices.\n",
      "\n",
      "The increased speed is achieved partly by using higher-frequency radio waves than current cellular networks.[1] However, higher-frequency radio waves have a shorter range than the frequencies used by previous cell phone towers, requiring smaller cells. So to ensure wide service, 5G networks operate on up to three frequency bands, low, medium, and high.[3][1] A 5G network will be composed of networks of up to 3 different types of cells, each requiring different antennas, each type giving a different tradeoff of download speed vs. distance and service area. 5G cellphones and wireless devices will connect to the network through the highest speed antenna within range at their location:\n",
      "\n",
      "Low-band 5G uses a similar frequency range to current 4G cellphones, 600-700 MHz, giving download speeds a little higher than 4G: 30-250 megabits per second (Mbit/s).[3] Low-band cell towers will have a range and coverage area similar to current 4G towers. Mid-band 5G uses microwaves of 2.5-3.7 GHz, currently allowing speeds of 100-900 Mbit/s, with each cell tower providing service up to several miles in radius. This level of service is the most widely deployed, and should be available in most metropolitan areas in 2020. Some countries are not implementing low-band, making this the minimum service level. High-band 5G currently uses frequencies of 25-39 GHz, near the bottom of the millimeter wave band, although higher frequencies may be used in the future. It often achieves download speeds of a gigabit per second (Gbit/s), comparable to cable internet. However, millimeter waves (mmWave or mmW) have a more limited range, requiring many small cells.[4] They have trouble passing through some types of walls and windows. Due to their higher costs, current plans are to deploy these cells only in dense urban environments and areas where crowds of people congregate such as sports stadiums and convention centers. The above speeds are those achieved in actual tests in 2020, and speeds are expected to increase during rollout.[3]\n",
      "\n",
      "The industry consortium setting standards for 5G is the 3rd Generation Partnership Project (3GPP).[1] It defines any system using 5G NR (5G New Radio) software as \"5G\", a definition that came into general use by late 2018. Minimum standards are set by the International Telecommunications Union (ITU). Previously, some reserved the term 5G for systems that deliver download speeds of 20 Gbit/s as specified in the ITU's IMT-2020 document.\n"
     ]
    }
   ],
   "source": [
    "test_data = df_test.content[16]\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.08485377579927444\t Topic: 0.045*\"mission\" + 0.018*\"mars\" + 0.015*\"chandrayaan\" + 0.015*\"orbiter\" + 0.015*\"astrosat\" + 0.012*\"orbit\" + 0.012*\"space\" + 0.012*\"spacecraft\" + 0.009*\"xray\" + 0.009*\"module\"\n",
      "Score: 0.09912040829658508\t Topic: 0.016*\"country\" + 0.016*\"economic\" + 0.016*\"product\" + 0.013*\"domestic\" + 0.013*\"data\" + 0.013*\"gross\" + 0.013*\"services\" + 0.011*\"transmission\" + 0.011*\"factor\" + 0.011*\"numbers\"\n",
      "Score: 0.020709555596113205\t Topic: 0.040*\"batsmen\" + 0.037*\"cricket\" + 0.029*\"game\" + 0.018*\"team\" + 0.015*\"runs\" + 0.011*\"score\" + 0.011*\"players\" + 0.011*\"bowler\" + 0.011*\"balls\" + 0.008*\"bowls\"\n",
      "Score: 0.05884911119937897\t Topic: 0.027*\"covid\" + 0.027*\"coronaviruses\" + 0.023*\"respiratory\" + 0.019*\"coronavirus\" + 0.019*\"spread\" + 0.019*\"virus\" + 0.016*\"people\" + 0.016*\"infected\" + 0.012*\"community\" + 0.012*\"symptoms\"\n",
      "Score: 0.06291854381561279\t Topic: 0.029*\"religious\" + 0.021*\"religions\" + 0.021*\"religion\" + 0.013*\"belief\" + 0.009*\"world\" + 0.009*\"people\" + 0.009*\"multiple\" + 0.009*\"principles\" + 0.009*\"life\" + 0.009*\"follow\"\n",
      "Score: 0.11241986602544785\t Topic: 0.020*\"global\" + 0.020*\"entrance\" + 0.020*\"warming\" + 0.017*\"main\" + 0.017*\"exam\" + 0.013*\"board\" + 0.012*\"india\" + 0.010*\"cricket\" + 0.010*\"examination\" + 0.010*\"causes\"\n",
      "Score: 0.0924508273601532\t Topic: 0.044*\"football\" + 0.038*\"politics\" + 0.019*\"political\" + 0.013*\"codes\" + 0.013*\"ball\" + 0.011*\"concepts\" + 0.010*\"players\" + 0.008*\"rugby\" + 0.008*\"rules\" + 0.008*\"definitions\"\n",
      "Score: 0.3277151584625244\t Topic: 0.020*\"intelligence\" + 0.017*\"brain\" + 0.015*\"neuralink\" + 0.011*\"artificial\" + 0.009*\"machines\" + 0.009*\"place\" + 0.009*\"inside\" + 0.009*\"wires\" + 0.008*\"device\" + 0.007*\"particular\"\n",
      "Score: 0.09705495834350586\t Topic: 0.030*\"team\" + 0.019*\"aiims\" + 0.015*\"singh\" + 0.015*\"medical\" + 0.013*\"carpool\" + 0.012*\"forensic\" + 0.011*\"share\" + 0.010*\"death\" + 0.010*\"mumbai\" + 0.009*\"board\"\n",
      "Score: 0.041174132376909256\t Topic: 0.029*\"data\" + 0.020*\"output\" + 0.018*\"device\" + 0.016*\"memory\" + 0.012*\"programs\" + 0.012*\"input\" + 0.012*\"software\" + 0.012*\"hardware\" + 0.012*\"components\" + 0.012*\"parts\"\n"
     ]
    }
   ],
   "source": [
    "bow_vector = dictionary.doc2bow(data_processing(test_data))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we took data related to technology, hence it is showing a score 0.3277151584625244 for a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
